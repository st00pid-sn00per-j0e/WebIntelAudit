Hereâ€™s the **refactored and improved version** of your `LightweightNLP` module, incorporating:

* Proper TF-IDF approximation with fallback
* Enhanced sentiment detection with negation handling
* Smarter summarization sentence ordering
* Improved regexes for better entity coverage
* Minor performance tweaks

```python
#!/usr/bin/env python3
"""
Improved Lightweight NLP Module
Optimized for minimal dependencies with extended capabilities
"""

import re
import json
import math
from typing import List, Dict, Tuple
from collections import Counter, defaultdict

class LightweightNLP:
    def __init__(self):
        self.stop_words = {
            'a', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'by', 'for',
            'from', 'has', 'have', 'he', 'in', 'is', 'it', 'its', 'of', 'on',
            'that', 'the', 'to', 'was', 'will', 'with', 'this', 'these', 'those',
            'they', 'them', 'their', 'what', 'which', 'who', 'when', 'where',
            'why', 'how', 'all', 'both', 'each', 'more', 'most', 'other', 'some',
            'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can',
            'just', 'should', 'now'
        }

        self.security_keywords = {
            'secure', 'encrypted', 'ssl', 'https', 'certificate', 'authentication',
            'authorization', 'vulnerability', 'exploit', 'injection', 'xss',
            'csrf', 'security', 'protection', 'firewall', 'antivirus', 'malware'
        }

        self.performance_keywords = {
            'fast', 'slow', 'performance', 'speed', 'optimize', 'cache',
            'loading', 'responsive', 'efficient', 'latency', 'bandwidth',
            'compression', 'minify', 'bundle', 'lazy', 'async', 'defer'
        }

        self.ux_keywords = {
            'user', 'experience', 'interface', 'design', 'accessibility',
            'usability', 'navigation', 'intuitive', 'responsive', 'mobile',
            'desktop', 'tablet', 'touchscreen', 'gesture', 'interaction'
        }

    def preprocess_text(self, text: str) -> str:
        text = text.lower()
        text = re.sub(r'<[^>]+>', ' ', text)
        text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)
        return ' '.join(text.split())

    def tokenize(self, text: str) -> List[str]:
        return text.split()

    def extract_keywords(self, text: str, num_keywords: int = 10) -> List[Tuple[str, float]]:
        preprocessed = self.preprocess_text(text)
        tokens = [w for w in self.tokenize(preprocessed) if w not in self.stop_words and len(w) > 3]
        total_words = len(tokens)
        if total_words == 0:
            return []

        freq = Counter(tokens)
        tfidf = {}
        for word, count in freq.items():
            tf = count / total_words
            idf = math.log(total_words / (1 + count))
            tfidf[word] = tf * idf

        return sorted(tfidf.items(), key=lambda x: x[1], reverse=True)[:num_keywords]

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        return {
            'emails': re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[a-zA-Z]{2,}\b', text),
            'urls': re.findall(r'http[s]?://[^\s]+', text),
            'phone_numbers': re.findall(r'\b(?:\+?\d{1,3})?[-.\s]?\(?\d{1,4}\)?[-.\s]?\d{3,4}[-.\s]?\d{4}\b', text),
            'dates': re.findall(r'\b(?:\d{1,2}[/-])?\d{1,2}[/-]\d{2,4}|\d{4}-\d{2}-\d{2}\b', text),
            'prices': re.findall(r'\$\d+(?:,\d{3})*(?:\.\d{2})?', text)
        }

    def analyze_sentiment(self, text: str) -> Dict:
        positive_words = {
            'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic',
            'love', 'perfect', 'best', 'awesome', 'nice', 'super', 'happy',
            'beautiful', 'brilliant', 'outstanding', 'positive', 'success'
        }

        negative_words = {
            'bad', 'terrible', 'awful', 'horrible', 'poor', 'worst', 'hate',
            'disappointing', 'useless', 'broken', 'fail', 'wrong', 'error',
            'problem', 'issue', 'bug', 'crash', 'slow', 'confusing', 'difficult'
        }

        negations = {"not", "no", "never", "none", "cannot"}

        tokens = self.tokenize(self.preprocess_text(text))
        pos, neg = 0, 0

        for i, word in enumerate(tokens):
            if word in positive_words:
                if i > 0 and tokens[i - 1] in negations:
                    neg += 1
                else:
                    pos += 1
            elif word in negative_words:
                if i > 0 and tokens[i - 1] in negations:
                    pos += 1
                else:
                    neg += 1

        total = pos + neg
        if total == 0:
            return {'positive': 0.5, 'negative': 0.5, 'neutral': 1.0}

        return {
            'positive': pos / total,
            'negative': neg / total,
            'overall': 'positive' if pos > neg else 'negative' if neg > pos else 'neutral',
            'confidence': abs(pos - neg) / total
        }

    def extract_topics(self, text: str) -> Dict[str, float]:
        tokens = set(self.tokenize(self.preprocess_text(text)))
        topics = {}
        if matches := tokens.intersection(self.security_keywords):
            topics['security'] = len(matches) / len(self.security_keywords)
        if matches := tokens.intersection(self.performance_keywords):
            topics['performance'] = len(matches) / len(self.performance_keywords)
        if matches := tokens.intersection(self.ux_keywords):
            topics['user_experience'] = len(matches) / len(self.ux_keywords)
        return topics

    def summarize_text(self, text: str, num_sentences: int = 3) -> str:
        sentences = re.split(r'(?<=[.!?])\s+', text)
        if len(sentences) <= num_sentences:
            return text.strip()

        keywords = [w for w, _ in self.extract_keywords(text, 20)]
        keyword_set = set(keywords)

        sentence_scores = []
        for i, sentence in enumerate(sentences):
            token_set = set(self.tokenize(self.preprocess_text(sentence)))
            score = len(token_set.intersection(keyword_set))
            sentence_scores.append((score, i, sentence.strip()))

        top_sentences = sorted(sentence_scores, reverse=True)[:num_sentences]
        top_sentences = sorted(top_sentences, key=lambda x: x[1])  # original order

        return ' '.join([s[2] for s in top_sentences])

    def analyze_web_content(self, text: str) -> Dict:
        return {
            'keywords': dict(self.extract_keywords(text, 15)),
            'entities': self.extract_entities(text),
            'sentiment': self.analyze_sentiment(text),
            'topics': self.extract_topics(text),
            'summary': self.summarize_text(text, 5),
            'word_count': len(self.tokenize(text)),
            'unique_words': len(set(self.tokenize(self.preprocess_text(text))))
        }


# Example usage for testing
if __name__ == "__main__":
    nlp = LightweightNLP()
    sample_text = """
    Welcome to our secure e-commerce platform! We provide fast, reliable service 
    with SSL encryption and excellent customer support. Our website loads quickly 
    and offers a great user experience on mobile and desktop devices. 
    Contact us at support@example.com or call +1-555-123-4567.
    """

    results = nlp.analyze_web_content(sample_text)
    print(json.dumps(results, indent=2))
```

---

### Summary of Improvements

| Feature       | Original      | Refactored                        |
| ------------- | ------------- | --------------------------------- |
| TF-IDF        | Self-weighted | Corrected w/ pseudo-IDF           |
| Regex         | Basic         | Improved (e.g., phone, date, URL) |
| Sentiment     | Count-based   | Handles negation                  |
| Summarization | Rank-only     | Preserves original order          |
| Output        | Basic         | Consistent & structured           |

Let me know if you want this module converted into a Flask microservice or Replit-ready API wrapper.
